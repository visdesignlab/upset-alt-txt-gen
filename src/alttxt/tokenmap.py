from email.policy import default
from this import s
from alttxt.models import DataModel
from alttxt.models import GrammarModel
from typing import cast

class TokenMap:
    """
    This class maps tokens from the grammar to strings.
    Each string is either defined directly in the mapping,
    or is the result of a function call. Functions called
    should be defined in this class, and should return a string.
    Result strings can contain tokens, which are represented
    surrounded by curly braces, e.g. {{token}}.
    While this class returns a string for each token fed to it,
    it is not responsible for the actual substitution of tokens
    or the overall generation of the text description.
    """
    def __init___(self, data: DataModel, grammar: GrammarModel) -> None:
        """
        Initialize the Grammar class. Note that internal values 
        are not recomputed if the data or grammar are changed.
        Params:
            data: Imported from a data file generated by Upset
            grammar: Imported from a grammar file generated by Upset
        """
        self.data = data
        self.grammar = grammar

        # Computations for commonly-used values are done here
        # and stored as class attributes.
        _max_idx = self.data.count.index(max(self.data.count))
        _min_idx = self.data.count.index(min(self.data.count))
        self.max_sets, self.max_size = self.data.membs[_max_idx], max(self.data.count)
        self.min_sets, self.min_size = self.data.membs[_min_idx], min(self.data.count)
        self.total_data = sum(self.data.count)
        self.max_set = max(self.data.sizes, key=self.data.sizes.get)
        self.min_set = min(self.data.sizes, key=self.data.sizes.get)
        self.max_set_size = self.data.sizes[self.max_set]
        self.min_set_size = self.data.sizes[self.min_set]
        self.total_set_size = sum(self.data.sizes.values())

        # This defines the mapping of tokens to strings/functions
        # As with the rest of this class, the curly braces surrounding
        # tokens are left out.
        # Generally, tokens which are easy to compute are done in the map,
        # whereas more complex tokens are done in functions.
        # Since functions are only executed on run, they can be used to
        # optimize by moving expensive tokens into fuctions.
        self.map = {
            "caption": self.grammar.caption,
            "title": self.grammar.title,
            "total": len(self.data.sets),
            "list_set_names": self.list_set_names,
            "x_min": min(self.data.count),
            "x_max": max(self.data.count),
            "x_inc": self.data.count[1] - self.data.count[0],
            "universal_set_size": sum(self.data.sizes.values()),
            "max_perc": round(100 * self.max_size / self.total_data, 2) + "%",
            "min_perc": round(100 * self.min_size / self.total_data, 2) + "%",
            "list_max_memberships": self.list_max_memberships,
            "list_min_memberships": self.list_min_memberships,
            "list_max_set_name": self.max_set,
            "list_min_set_name": self.min_set,
            "max_set_perc": round(100 * self.max_set_size / self.total_set_size, 2) + "%",
            "min_set_perc": round(100 * self.min_set_size / self.total_set_size, 2) + "%",
            "max_dev": max(self.data.devs),
            "min_dev": min(self.data.devs),
            "list_max_dev_membership": self.list_max_dev_membership,
            "list_min_dev_membership": self.list_min_dev_membership,
        }

    def get_token(self, token: str) -> str:
        """
        Return the string associated with the given token.
        Throws an exception if the given token is not mapped
        """
        if token not in self.map:
            raise Exception("Token not found: " + token)

        result = self.map[token]
        if type(result) == float:
            return round(result, 2)
        elif callable(result):
            return result()
        else:
            return result
    
    def list_max_dev_membership(self):
        """
        Return the union of sets that has the highest deviation
        from its expected cardinality
        """
        _max_dev_idx = self.data.devs.index(self.map["max_dev"])
        max_dev_set = self.data.membs[_max_dev_idx]
        
        if len(max_dev_set) > 1:
            return ", ".join(list(max_dev_set)[:-1]) + " and " + list(max_dev_set)[-1]
        else:
            return list(max_dev_set)[0]

    def list_min_dev_membership(self):
        """
        Return the union of sets that has the lowest deviation
        from its expected cardinality
        """
        _min_dev_idx = self.data.devs.index(self.map["min_dev"])
        min_dev_set = self.data.membs[_min_dev_idx]
    
        if len(min_dev_set) > 1:
            return ", ".join(list(min_dev_set)[:-1]) + " and " + list(min_dev_set)[-1]
        else:
            return list(min_dev_set)[0]

    def list_max_memberships(self) -> str:
        """
        Returns a string of the set names with the maximum number of
        memberships, separated by commas, with the last two separated by "and".
        """
        if self.max_sets > 1:
            return ", ".join(list(self.max_sets)[:-1]) + "and" + list(self.max_sets)[-1]
        else:
            return list(self.max_sets)[0]

    def list_min_memberships(self) -> str:
        """
        Returns a string of the set names with the minimum number of
        memberships, separated by commas, with the last two separated by "and".
        """
        if self.min_sets > 1:
            return ", ".join(list(self.min_sets)[:-1]) + "and" + list(self.min_sets)[-1]
        else:
            return list(self.min_sets)[0]

    def list_set_names(self) -> str:
        """
        Returns a string of the set names separated by commas,
        with the last two separated by "and".
        """
        return ", ".join(self.data.sets[:-1]) + " and " + self.data.sets[-1]